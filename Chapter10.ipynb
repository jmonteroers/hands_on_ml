{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c51d99-f2a6-4adf-92c1-6db396bb3581",
   "metadata": {},
   "source": [
    "## From biological to artifical neurons\n",
    "\n",
    "Origin: McCulloch and Pitts' 1943 paper \"A Logical Calculus of Ideas Immanent in Nervous Activity\". This paper presented a simplified computational model of how biological neurons might work together in animal brains to perform complex computations using propotional logic.\n",
    "\n",
    "Long winter followed, till the 1980s. In the early 1980s, new architectures were invented and better training techniques were developed.\n",
    "\n",
    "Currently, there's another wave of interest growing on ANNs. Why not stop this time?\n",
    "- Huge amounts of data, and neural networks outperform other ML models on very large and complex problems\n",
    "\n",
    "- Increase in computing power\n",
    "\n",
    "- Good results lead to investment, and investment leads to good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe3e68-41ba-4aae-afcc-d8b8ec98afb1",
   "metadata": {},
   "source": [
    "## Check Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d25b8aa-bd2f-4727-97f7-ee365f874fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ced6e-41a1-49af-a8e6-feba9b2ad8ec",
   "metadata": {},
   "source": [
    "## Build Image classifier using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880a1485-1802-4292-9cad-dc4541adcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cbca42-dbd1-40a2-b0ea-ba25abfff27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 17s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2e49e-7e68-4945-ac61-241af1f85111",
   "metadata": {},
   "source": [
    "Note that the features are represented as a 28x28 array, instead of a 1D array of size 784. Plus, pixel intensities are represented as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25eb77f-fbfb-4d33-a6a4-2019c33b7555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa772f49-19ea-40ce-a6d5-efdafb7bb162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7620ec5-b604-4c64-a83f-65035e070e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0, 5:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf4500-a273-4c5c-8443-ac9a6f21e2ea",
   "metadata": {},
   "source": [
    "We already have a train and test set, but we are missing a validation set. Plus, for Gradient Descent we need to scale the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e93911-618a-4c9d-8c7a-899e050c70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pixel_intensity(*args):\n",
    "    return [arg/255.0 for arg in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e7cfc3-1a33-4bfd-b6ef-33b9d5a5357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test = scale_pixel_intensity(X_train_full, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b3b0774-57ab-4834-a717-3b98dea3e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0, 5:7, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68cbba-2209-42d8-bbf7-8c66a9630684",
   "metadata": {},
   "source": [
    "Nice, we've scaled the input! Now, let's divide the arrays into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8127635b-e61c-4b57-b2c2-84f776a50331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_train(arr, obs_val=5000):\n",
    "    return arr[:obs_val], arr[obs_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af012608-d0df-4764-b562-7724cc3c724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_train = split_val_train(X_train_full)\n",
    "y_val, y_train = split_val_train(y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78577a33-8307-4943-b58d-86e4d3d78a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    " \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f67b176f-df9e-457e-a9b8-b0aa3094dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad4060-886c-45af-b6d6-d01061ac096a",
   "metadata": {},
   "source": [
    "### Create the model using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb3fddfb-2765-4fff-b1fb-9221639cbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential model. Simplest model for neural networks, single stack of layers connected sequentially\n",
    "model = keras.models.Sequential()\n",
    "# flattens the array\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# Dense contains all the connection weights between the neurons and their inputs\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "# softmax used as classes are exclusive\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60a93e1b-23bd-4c0b-93fa-768e4227d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to specify a model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac764df6-255a-43b8-b494-dbc728c0dd69",
   "metadata": {},
   "source": [
    "Checking the layers of the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e27e097-ca33-4fb4-a2da-02c97264ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c29d2-2392-4930-8bf1-b126bed4519e",
   "metadata": {},
   "source": [
    "#### Understanding the number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d48cb-580e-4502-8f37-504af74febfa",
   "metadata": {},
   "source": [
    "- The Flatten layers is simply an input operation, so it has 0 parameters\n",
    "\n",
    "- The dense layers, however, have to estimate all values of the weight matrix, plus the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89c72022-38de-4d74-a4da-317c897a3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first layer\n",
    "weights_in_matrix = 784*300\n",
    "bias_terms = 300\n",
    "weights_in_matrix + bias_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fa98988-0e90-4a80-87cb-6ed167e0f665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30100, 1010)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other weights\n",
    "301*100, 101*10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce019385-c816-4bc1-9c38-e29c2f89f1cf",
   "metadata": {},
   "source": [
    "#### Accessing the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9463b10-456a-4b8b-b2ad-b4a9d04a83ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x189c46250>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x189c46610>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x189c46a60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x189c46a90>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2252ce26-2585-4ae7-8348-446e5a6d78f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_6'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d2a3e05-8f10-4259-857a-87efad6ca6d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense_3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-7904b872f4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# access by name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dense_3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.Envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: dense_3."
     ]
    }
   ],
   "source": [
    "# access by name\n",
    "model.get_layer('dense_3') is model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32d973b9-035e-4aa2-b4ff-35334b9cc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access weights and biases of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a4d3f93-3676-451e-a2c7-caa5e05f2a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense_3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-306565c6505d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dense_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: dense_3."
     ]
    }
   ],
   "source": [
    "hidden1 = model.get_layer('dense_3')\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbe84a-37d6-4b1a-a954-ce0b3db3becb",
   "metadata": {},
   "source": [
    "Notice that the weights have already been initialised randomly! To use a different initialisation method, set `kernel_initializer` or `bias_initializer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fec620f0-65e8-45ab-81d3-484d4ba130f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 300),\n",
       " array([ 0.04552876,  0.02128465,  0.05327184, -0.0100558 , -0.00590967,\n",
       "         0.03044536,  0.00317791,  0.03155639, -0.04547326,  0.05562884],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, weights[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64a1babb-51a8-4dd3-8bb7-263bf464ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d6148-858f-4b9c-8242-096b44534bdb",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b291b7ea-3f79-4b5a-8cdf-0fc15e6c09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab5cb6-a5b7-4d07-98e5-be26e5f6d1f2",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- loss\n",
    "  - parse, because the target class is not a one-hot vector, but integers from 0 to 9\n",
    "  - categorical, since we are predicting multiple exclusive classes; otherwise, we would use \"sigmoid\" in output layer, and \"binary_crossentropy\"\n",
    "- optimizer: simple stochastic gradient descent, i.e. the backpropagation algorithm. We can tune the learning rate by adding the `lr` parameter and use `keras.optimizer.SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8bd56d-bdb7-4707-8e6e-1ada6c836365",
   "metadata": {},
   "source": [
    "#### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac9ee0a8-d07f-493e-a50f-a4777f09faff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c98ad773-b47f-49cd-b09e-49ca80805326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 911us/step - loss: 0.7285 - accuracy: 0.7588 - val_loss: 0.5018 - val_accuracy: 0.8276\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.4884 - accuracy: 0.8307 - val_loss: 0.4369 - val_accuracy: 0.8502\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 1s 862us/step - loss: 0.4430 - accuracy: 0.8453 - val_loss: 0.4155 - val_accuracy: 0.8568\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 1s 864us/step - loss: 0.4145 - accuracy: 0.8545 - val_loss: 0.3903 - val_accuracy: 0.8654\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.3957 - accuracy: 0.8603 - val_loss: 0.3765 - val_accuracy: 0.8674\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 1s 864us/step - loss: 0.3799 - accuracy: 0.8649 - val_loss: 0.3666 - val_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 1s 865us/step - loss: 0.3665 - accuracy: 0.8685 - val_loss: 0.3649 - val_accuracy: 0.8752\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 896us/step - loss: 0.3545 - accuracy: 0.8729 - val_loss: 0.3531 - val_accuracy: 0.8778\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 1s 870us/step - loss: 0.3459 - accuracy: 0.8770 - val_loss: 0.3539 - val_accuracy: 0.8764\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 875us/step - loss: 0.3351 - accuracy: 0.8791 - val_loss: 0.3373 - val_accuracy: 0.8798\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 1s 865us/step - loss: 0.3276 - accuracy: 0.8845 - val_loss: 0.3609 - val_accuracy: 0.8726\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 1s 865us/step - loss: 0.3193 - accuracy: 0.8851 - val_loss: 0.3419 - val_accuracy: 0.8774\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 875us/step - loss: 0.3129 - accuracy: 0.8888 - val_loss: 0.3447 - val_accuracy: 0.8758\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.3065 - accuracy: 0.8897 - val_loss: 0.3233 - val_accuracy: 0.8830\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 1s 870us/step - loss: 0.3000 - accuracy: 0.8920 - val_loss: 0.3243 - val_accuracy: 0.8848\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 911us/step - loss: 0.2934 - accuracy: 0.8953 - val_loss: 0.3276 - val_accuracy: 0.8826\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 1s 863us/step - loss: 0.2885 - accuracy: 0.8945 - val_loss: 0.3171 - val_accuracy: 0.8900\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 1s 871us/step - loss: 0.2831 - accuracy: 0.8974 - val_loss: 0.3276 - val_accuracy: 0.8812\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.2776 - accuracy: 0.8998 - val_loss: 0.3169 - val_accuracy: 0.8834\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 1s 868us/step - loss: 0.2738 - accuracy: 0.9005 - val_loss: 0.3178 - val_accuracy: 0.8870\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 879us/step - loss: 0.2684 - accuracy: 0.9039 - val_loss: 0.3056 - val_accuracy: 0.8898\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 1s 868us/step - loss: 0.2634 - accuracy: 0.9041 - val_loss: 0.3065 - val_accuracy: 0.8862\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 884us/step - loss: 0.2594 - accuracy: 0.9057 - val_loss: 0.3053 - val_accuracy: 0.8924\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 1s 868us/step - loss: 0.2537 - accuracy: 0.9085 - val_loss: 0.2995 - val_accuracy: 0.8878\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.2506 - accuracy: 0.9096 - val_loss: 0.3024 - val_accuracy: 0.8924\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 1s 870us/step - loss: 0.2458 - accuracy: 0.9118 - val_loss: 0.3051 - val_accuracy: 0.8890\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 1s 869us/step - loss: 0.2413 - accuracy: 0.9133 - val_loss: 0.3010 - val_accuracy: 0.8898\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 1s 867us/step - loss: 0.2375 - accuracy: 0.9145 - val_loss: 0.3124 - val_accuracy: 0.8876\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 1s 864us/step - loss: 0.2344 - accuracy: 0.9154 - val_loss: 0.3064 - val_accuracy: 0.8888\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 1s 872us/step - loss: 0.2302 - accuracy: 0.9175 - val_loss: 0.2965 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  X_train, y_train, epochs=30, validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3355da-10ec-49e7-b2ac-c96445984cf9",
   "metadata": {},
   "source": [
    "Note: instead of passing `validation_data`, you can pass `validation_split=.1` to use 10 % of the data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a4bba79-769c-4c8a-a9a2-caf50897d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1547/1547 [==============================] - 1s 900us/step - loss: 0.2262 - accuracy: 0.9189 - val_loss: 0.2263 - val_accuracy: 0.9153\n",
      "Epoch 2/15\n",
      "1547/1547 [==============================] - 1s 886us/step - loss: 0.2232 - accuracy: 0.9197 - val_loss: 0.2291 - val_accuracy: 0.9129\n",
      "Epoch 3/15\n",
      "1547/1547 [==============================] - 1s 885us/step - loss: 0.2199 - accuracy: 0.9214 - val_loss: 0.2353 - val_accuracy: 0.9129\n",
      "Epoch 4/15\n",
      "1547/1547 [==============================] - 1s 886us/step - loss: 0.2152 - accuracy: 0.9217 - val_loss: 0.2315 - val_accuracy: 0.9136\n",
      "Epoch 5/15\n",
      "1547/1547 [==============================] - 1s 887us/step - loss: 0.2124 - accuracy: 0.9238 - val_loss: 0.2397 - val_accuracy: 0.9067\n",
      "Epoch 6/15\n",
      "1547/1547 [==============================] - 1s 886us/step - loss: 0.2084 - accuracy: 0.9242 - val_loss: 0.2352 - val_accuracy: 0.9109\n",
      "Epoch 7/15\n",
      "1547/1547 [==============================] - 1s 885us/step - loss: 0.2054 - accuracy: 0.9257 - val_loss: 0.2435 - val_accuracy: 0.9093\n",
      "Epoch 8/15\n",
      "1547/1547 [==============================] - 1s 903us/step - loss: 0.2026 - accuracy: 0.9265 - val_loss: 0.2349 - val_accuracy: 0.9142\n",
      "Epoch 9/15\n",
      "1547/1547 [==============================] - 1s 900us/step - loss: 0.1999 - accuracy: 0.9285 - val_loss: 0.2473 - val_accuracy: 0.9056\n",
      "Epoch 10/15\n",
      "1547/1547 [==============================] - 1s 888us/step - loss: 0.1962 - accuracy: 0.9304 - val_loss: 0.2339 - val_accuracy: 0.9113\n",
      "Epoch 11/15\n",
      "1547/1547 [==============================] - 1s 892us/step - loss: 0.1926 - accuracy: 0.9312 - val_loss: 0.2444 - val_accuracy: 0.9105\n",
      "Epoch 12/15\n",
      "1547/1547 [==============================] - 1s 888us/step - loss: 0.1903 - accuracy: 0.9323 - val_loss: 0.2490 - val_accuracy: 0.9071\n",
      "Epoch 13/15\n",
      "1547/1547 [==============================] - 1s 888us/step - loss: 0.1877 - accuracy: 0.9331 - val_loss: 0.2357 - val_accuracy: 0.9118\n",
      "Epoch 14/15\n",
      "1547/1547 [==============================] - 1s 886us/step - loss: 0.1841 - accuracy: 0.9353 - val_loss: 0.2353 - val_accuracy: 0.9109\n",
      "Epoch 15/15\n",
      "1547/1547 [==============================] - 1s 891us/step - loss: 0.1812 - accuracy: 0.9351 - val_loss: 0.2521 - val_accuracy: 0.9016\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  X_train, y_train, epochs=15, validation_split=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df474ef-2894-4e05-963d-631fd37793e2",
   "metadata": {},
   "source": [
    "The fit method returns a `History` object that contains `params`, `epoch` (the list of epochs it went through), and history, a dictionary containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "520d9437-8a62-4234-b957-1ce4f3ab4dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 15, 'steps': 1547}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffdb14ec-9965-498d-b3c8-630af55ea3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5cea051-b503-4709-8068-b0ec7e3bb0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5136e83-187b-480d-8ef4-26a75843d53f",
   "metadata": {},
   "source": [
    "Let's use this history dictionary to represent the evolution of accuracy over the number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbe24249-228b-4649-871f-89d2a7a8ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 1.0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_accuracy = {'accuracy': history.history['accuracy'], 'validation_accuracy': history.history['val_accuracy']}\n",
    "pd.DataFrame(hist_accuracy).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.8, 1)  # set the vertical range to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2e589-3e8c-43bb-8863-2250bce79558",
   "metadata": {},
   "source": [
    "The train and validation errors are not computed in the same way, which may be misleading. While the train error is computed as a running mean of the batches within each epoch, the validation error is computed at the end of each epoch on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45d0c46e-f3a2-4da4-9db3-f611d06b4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 613us/step - loss: 0.3383 - accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33828675746917725, 0.8798999786376953]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6524cf-0c5d-4b80-b856-bfaef73a3275",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4cac1c5-b421-4af6-bd32-96d3b71c5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef401af7-58f1-4e0f-99c8-5ca034449474",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fee82644-0f96-4a30-9bab-7ab529c1931d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "275d4904-1227-4b4e-bddd-e8a1c020d540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "        0.998],\n",
       "       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c6e96-bcb9-4f18-a622-ccb6eddf2cb9",
   "metadata": {},
   "source": [
    "To directly choose the largest probability to do classification, you can use `predict_classes` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc5cd2f2-3802-4b86-87c4-4f405cb14305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "447e4d23-a56a-4ae4-94ca-246a09c6a92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle Boat', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1574e-454a-4f57-8f50-c3cde36dd1c3",
   "metadata": {},
   "source": [
    "Let's check these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b519ef80-7956-4315-8352-d643bcae637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle Boat', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_test[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84afae-c5db-4329-b623-436723813333",
   "metadata": {},
   "source": [
    "## Regression MLP using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11462f59-5288-41ab-89ee-d74f20e163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b68e370f-2dd2-41a8-beec-bc4b138e54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbe32a31-3e9b-43cf-8b01-405db410c1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing.data), type(housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9782391f-3618-4396-8ccb-4a6a2d0ccff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "  housing.data, housing.target\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13c764ce-a21c-42a6-8d3e-e918be5bd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1391e1-c96f-47b3-8ffa-08fea838ed81",
   "metadata": {},
   "source": [
    "Differences w.r.t. Neural Network for classification:\n",
    "- Output, single neuron with no activation function\n",
    "- Need to change the loss function to `mean_squared_error`, for example\n",
    "- Since dataset is quite noisy, try to use fewer neurons to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e3ef94c-a88f-42a2-967f-b7d34a266e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cba5c217-60e3-400c-9306-c63eb679fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "363efdd3-4b81-49cb-aac2-2adad15d39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.8327 - val_loss: 0.6541\n",
      "Epoch 2/15\n",
      "363/363 [==============================] - 0s 584us/step - loss: 0.4911 - val_loss: 0.5394\n",
      "Epoch 3/15\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.4396 - val_loss: 0.6589\n",
      "Epoch 4/15\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.4272 - val_loss: 0.6417\n",
      "Epoch 5/15\n",
      "363/363 [==============================] - 0s 589us/step - loss: 0.4079 - val_loss: 0.4158\n",
      "Epoch 6/15\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.3907 - val_loss: 0.4027\n",
      "Epoch 7/15\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3820 - val_loss: 0.3835\n",
      "Epoch 8/15\n",
      "363/363 [==============================] - 0s 592us/step - loss: 0.3756 - val_loss: 0.3802\n",
      "Epoch 9/15\n",
      "363/363 [==============================] - 0s 617us/step - loss: 0.3747 - val_loss: 0.3769\n",
      "Epoch 10/15\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3686 - val_loss: 0.3988\n",
      "Epoch 11/15\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.3658 - val_loss: 0.3769\n",
      "Epoch 12/15\n",
      "363/363 [==============================] - 0s 586us/step - loss: 0.3616 - val_loss: 0.3706\n",
      "Epoch 13/15\n",
      "363/363 [==============================] - 0s 592us/step - loss: 0.3634 - val_loss: 0.3711\n",
      "Epoch 14/15\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3574 - val_loss: 0.3731\n",
      "Epoch 15/15\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3548 - val_loss: 0.3676\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5230448e-ef83-4091-9f7c-e48b3ec0d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 439us/step - loss: 0.3607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36069419980049133"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4aaf5db1-3108-45b3-9488-e578ade76f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8906a639-e491-4b7b-a052-b2e1616f3b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.8898067],\n",
       "        [1.0986954],\n",
       "        [1.0035229]], dtype=float32),\n",
       " array([1.928, 0.929, 0.738]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new), y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf2997c2-dbf3-4909-8be5-9f318c22fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec0040c0-b5b3-4379-9359-aea763a3a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5160, 1), (5160, 1))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef4b2490-9d7d-4c2e-bda0-11aa1eb9f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e92f41f7-83a6-4154-97a6-e146fe41f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error = np.abs(y_pred - y_test) / y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "20ab97c0-cded-42b2-83f0-677c47e1a70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01980978],\n",
       "       [0.18266458],\n",
       "       [0.35978709],\n",
       "       [0.09721315],\n",
       "       [0.35332399]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_error[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "777f251c-3a8b-4f5b-8e63-ecf54bab44ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.216746007920683, 24.840768853249642)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*np.median(abs_error), 100*np.mean(abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "157054bc-e63c-4680-b820-a038a71982f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_error(y_pred, y_test):\n",
    "    abs_error = np.abs(y_pred - y_test) / y_test\n",
    "    return 100*np.median(abs_error), 100*np.mean(abs_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c603a-db9e-473f-b1b9-2921a5d8fc53",
   "metadata": {},
   "source": [
    "## Build Complex Models using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7942fe-992a-4b5e-b692-fb896ddc765c",
   "metadata": {},
   "source": [
    "We are going to build a Wide & Deep Neural Network. The idea is to have a layer before the output layer where we concatenate the inputs and the result of a deep neural network. This allows to have simple and deep patterns in the same neural network at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3ada9c9-8c8c-4dbd-a720-a243f2e4e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])  # describes input (e.g. shape and dtype)\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)  # notice how we pass the input as an argument!\n",
    "hidden2 = keras.layers.Dense(10, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "675d10e1-0f88-48e9-b96f-2dfb0844fb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           310         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 18)           0           input_2[0][0]                    \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            19          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "18fe80e0-89a7-45d0-954a-d828d3f2360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 1.0009 - val_loss: 7.7643\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.6227 - val_loss: 1.3954\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.5029 - val_loss: 1.0457\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4532 - val_loss: 0.4398\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.4129 - val_loss: 0.4243\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.4043 - val_loss: 0.4427\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.4087 - val_loss: 0.3918\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3857 - val_loss: 0.3999\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.3701 - val_loss: 0.3754\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.3638 - val_loss: 0.3701\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.3632 - val_loss: 0.3603\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.3564 - val_loss: 0.3605\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.3584 - val_loss: 0.3640\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.3498 - val_loss: 0.5543\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.3847 - val_loss: 0.3732\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.3514 - val_loss: 0.3527\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.3425 - val_loss: 0.3461\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.3411 - val_loss: 0.3523\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.3348 - val_loss: 0.3406\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.3344 - val_loss: 0.3429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ab0ccd0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b236f509-adf8-49ee-8986-9c128189f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 700us/step - loss: 0.3477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3476766347885132"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ba170ff6-0bfe-4eff-9c29-3bce745e17f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.6571113392156, 24.197662874212607)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_abs_error(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff761f-389e-42ba-b56e-154fa8e54e59",
   "metadata": {},
   "source": [
    "The results stay more or less unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457ab90-8542-4aa2-a8e3-9ffc5432fa19",
   "metadata": {},
   "source": [
    "## Using Tensorboard for Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972723d2-fd03-486f-a30d-0eaa655ce570",
   "metadata": {},
   "source": [
    "First step is defining the root log directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "20483737-1b93-4974-adcb-c4ca40e9410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3aa2a06b-fd5c-4fd3-8c57-f8656c36b6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2021_06_26-18_57_26'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094eb32-8b0e-4800-a321-a4f89a841610",
   "metadata": {},
   "source": [
    "Now we are ready to use the Tensorboard callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e4689f46-567a-46a0-9234-9a6bfcb2f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2782 - val_loss: 0.3053\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.2796 - val_loss: 0.3080\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.2789 - val_loss: 0.3075\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 653us/step - loss: 0.2781 - val_loss: 0.4788\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.2804 - val_loss: 0.3507\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.2773 - val_loss: 0.3517\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.2915 - val_loss: 0.3120\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.2779 - val_loss: 0.3623\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.2843 - val_loss: 0.3059\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.2768 - val_loss: 0.3004\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.2779 - val_loss: 0.3082\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.2777 - val_loss: 0.3079\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.2789 - val_loss: 0.3077\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.2761 - val_loss: 0.3071\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.2764 - val_loss: 0.4346\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.2884 - val_loss: 0.3026\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.2765 - val_loss: 0.3247\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.2758 - val_loss: 0.3262\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.2764 - val_loss: 0.4210\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.2818 - val_loss: 0.3057\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.2750 - val_loss: 0.3134\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.2756 - val_loss: 0.3158\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.2741 - val_loss: 0.3038\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.2773 - val_loss: 0.3093\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 667us/step - loss: 0.2739 - val_loss: 0.5785\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.3175 - val_loss: 0.3110\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.2752 - val_loss: 0.3019\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.2748 - val_loss: 0.3186\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.2752 - val_loss: 0.3065\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.2732 - val_loss: 0.4079\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "db1729da-20d8-4b31-b290-11265c9cea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmontero/.Envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 938us/step - loss: 0.2749 - val_loss: 0.3016\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.2736 - val_loss: 0.2984\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.2727 - val_loss: 0.3127\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.2730 - val_loss: 0.3013\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.2730 - val_loss: 0.3015\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.2755 - val_loss: 0.3481\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.2725 - val_loss: 0.3001\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 667us/step - loss: 0.2722 - val_loss: 0.3048\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.2725 - val_loss: 0.3106\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.2715 - val_loss: 0.2963\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.2726 - val_loss: 0.3039\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.2715 - val_loss: 0.3139\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.2712 - val_loss: 0.3072\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 648us/step - loss: 0.2734 - val_loss: 0.3031\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.2713 - val_loss: 0.2979\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.2712 - val_loss: 0.3704\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.2721 - val_loss: 0.3072\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.2702 - val_loss: 0.3036\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.2699 - val_loss: 0.3063\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.2750 - val_loss: 0.3375\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.2732 - val_loss: 0.3024\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 650us/step - loss: 0.2719 - val_loss: 0.3175\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.2714 - val_loss: 0.3676\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.2905 - val_loss: 0.3219\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 654us/step - loss: 0.2750 - val_loss: 0.3025\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.2709 - val_loss: 0.2928\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.2700 - val_loss: 0.2948\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.2691 - val_loss: 0.3102\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.2685 - val_loss: 0.3240\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.2716 - val_loss: 0.2990\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=10**(-2)))\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05f8dc-51ce-4579-b4a1-c97b00dbf188",
   "metadata": {},
   "source": [
    "We can even run Tensorboard directly from this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "99d7f9c2-77e7-460b-b6c1-9d0cb2972e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bf9b9d1a-e2be-4ddc-bffb-03e8c584d342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8861), started 0:02:00 ago. (Use '!kill 8861' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8271e3fdb11536\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8271e3fdb11536\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir='./my_logs' --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
